{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8649149,"sourceType":"datasetVersion","datasetId":5180708},{"sourceId":9378336,"sourceType":"datasetVersion","datasetId":5689032},{"sourceId":9415211,"sourceType":"datasetVersion","datasetId":5717928}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install split-folders\nfrom keras.applications import ResNet101, DenseNet121\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Activation, Add, Lambda, GlobalMaxPooling2D, Concatenate, Dropout, Flatten\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport splitfolders  # or import split_folders\nimport tensorflow as tf\nfrom keras.layers import Input, Multiply\nfrom tensorflow.keras import mixed_precision\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import SeparableConv1D","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:27:47.594738Z","iopub.execute_input":"2024-10-10T23:27:47.595006Z","iopub.status.idle":"2024-10-10T23:28:04.226954Z","shell.execute_reply.started":"2024-10-10T23:27:47.594980Z","shell.execute_reply":"2024-10-10T23:28:04.226108Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: split-folders in /opt/conda/lib/python3.10/site-packages (0.5.1)\n","output_type":"stream"},{"name":"stderr","text":"2024-10-10 23:28:00.790071: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-10-10 23:28:00.790157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-10-10 23:28:00.792012: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"splitfolders.ratio('/kaggle/input/datasetss/tomato_state', output=\"output\", seed=1337, ratio=(.8, .2), group_prefix=None) # default values\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:28:04.228107Z","iopub.execute_input":"2024-10-10T23:28:04.228656Z","iopub.status.idle":"2024-10-10T23:28:07.703671Z","shell.execute_reply.started":"2024-10-10T23:28:04.228626Z","shell.execute_reply":"2024-10-10T23:28:07.702736Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Copying files: 3196 files [00:03, 923.21 files/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training dataset :\")# Définir le générateur d'images pour l'entraînement\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n#                                  rotation_range=40,\n#                                  width_shift_range=0.2,\n#                                  height_shift_range=0.2,\n#                                  shear_range=0.2,\n#                                  zoom_range=0.2,\n#                                  horizontal_flip=True,\n#                                  vertical_flip=True,\n#                                  featurewise_std_normalization=True,\n#                                  fill_mode='nearest'      # Remplissage des pixels vides après transformation\n)\n\n# Créer le dataset d'entraînement\ntrain_dataset = train_datagen.flow_from_directory('./output/train',\n                                                  target_size=(256,256),\n                                                  color_mode='rgb',\n                                                  batch_size=32,\n                                                  class_mode='categorical',\n                                                  shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:28:07.704846Z","iopub.execute_input":"2024-10-10T23:28:07.705134Z","iopub.status.idle":"2024-10-10T23:28:07.827341Z","shell.execute_reply.started":"2024-10-10T23:28:07.705109Z","shell.execute_reply":"2024-10-10T23:28:07.826529Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Training dataset :\nFound 2556 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Validation dataset :\")\n# Générateur d'images pour la validation (sans augmentation)\nval_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,\n#                                 rotation_range=40,\n#                                 width_shift_range=0.2,\n#                                 height_shift_range=2.2,\n#                                 shear_range=0.2,\n#                                 zoom_range=0.2,\n#                                 horizontal_flip=True,\n#                                 vertical_flip=True,\n#                                 featurewise_std_normalization=True,\n#                                 fill_mode='nearest'\n                              ) \n\n\n\n# Créer le dataset de validation\nval_dataset = val_datagen.flow_from_directory('./output/val',\n                                              target_size=(256,256),\n                                              color_mode='rgb',\n                                              batch_size=32,\n                                              class_mode='categorical',\n                                              shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:28:07.830600Z","iopub.execute_input":"2024-10-10T23:28:07.830931Z","iopub.status.idle":"2024-10-10T23:28:07.877266Z","shell.execute_reply.started":"2024-10-10T23:28:07.830905Z","shell.execute_reply":"2024-10-10T23:28:07.876366Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Validation dataset :\nFound 640 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def ssd_extractor(x):\n    conv6 = layers.SeparableConv2D(1024, (2, 2), padding='same', activation='relu', name='conv6')(x)\n    conv7 = layers.SeparableConv2D(1024, (2, 2), padding='same', activation='relu', name='conv7')(conv6)\n\n    feature_layers = [conv7]\n    for filters, name in [(512, 'conv8_2'), (512, 'conv9_2')]:\n        feature_layers.append(tf.keras.layers.Conv2D(filters, (1, 1), activation='relu', padding='same', name=name)(feature_layers[-1]))\n        features = layers.Concatenate(name='ssd_feature_concat')(feature_layers)\n\n    \n    return features\n    \n# Set mixed precision policy\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:28:07.878319Z","iopub.execute_input":"2024-10-10T23:28:07.878634Z","iopub.status.idle":"2024-10-10T23:28:07.885674Z","shell.execute_reply.started":"2024-10-10T23:28:07.878609Z","shell.execute_reply":"2024-10-10T23:28:07.884792Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Add, SeparableConv2D, Conv2D, Layer\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.models import Model\n\nclass ECALayer(Layer):\n    def __init__(self, **kwargs):\n        super(ECALayer, self).__init__(**kwargs)\n    \n    def build(self, input_shape):\n        pass  # Add your custom layer implementation here if needed\n    \n    def call(self, inputs):\n        return inputs  # Modify based on actual ECA functionality\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:28:07.886912Z","iopub.execute_input":"2024-10-10T23:28:07.887258Z","iopub.status.idle":"2024-10-10T23:28:07.897417Z","shell.execute_reply.started":"2024-10-10T23:28:07.887226Z","shell.execute_reply":"2024-10-10T23:28:07.896585Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.applications.resnet import ResNet101, preprocess_input\nfrom keras.layers import Input, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, Flatten\nfrom keras.models import Model\nfrom keras.regularizers import l2\n\ninput_shape = (256, 256, 3)\ninputs = Input(shape=input_shape)\npreprocessed_input = preprocess_input(inputs)  # Use ResNet101 preprocessing\n\n# Charger et prétraiter le modèle ResNet101\nbase_model = ResNet101(include_top=False, weights='imagenet', input_shape=input_shape)\nbase_model.trainable = False  # Geler les couches du modèle de base\n\n# Débloquer certaines couches supérieures (optionnel)\n# for layer in base_model.layers[-10:]:\n#     layer.trainable = True\n\n# Passer les entrées à travers le modèle de base\nx = base_model(preprocessed_input)\n# x = ECALayer(x)\n# x = ssd_extractor(x)\n# Ajouter des couches de classification\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\nx = Dropout(0.2)(x)\n# # x = BatchNormalization()(x)\nx = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\nx = Dropout(0.2)(x)\n# x = BatchNormalization()(x)\nx = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n# x = BatchNormalization()(x)\nx = Dropout(0.2)(x)\n# x = Flatten()(x)\noutputs = Dense(2, activation='softmax')(x)  # Pour une classification binaire\n\n# Créer le modèle complet\nmodel = Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:25.059264Z","iopub.execute_input":"2024-10-10T23:29:25.059917Z","iopub.status.idle":"2024-10-10T23:29:27.286961Z","shell.execute_reply.started":"2024-10-10T23:29:25.059884Z","shell.execute_reply":"2024-10-10T23:29:27.285926Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# for layer in model.layers[-10:]:\n#     layer.trainable=True\n# for layer in model.layers[20:]:\n#     layer.trainable=True","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:27.288752Z","iopub.execute_input":"2024-10-10T23:29:27.289075Z","iopub.status.idle":"2024-10-10T23:29:27.294852Z","shell.execute_reply.started":"2024-10-10T23:29:27.289050Z","shell.execute_reply":"2024-10-10T23:29:27.293923Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Afficher la structure du modèle complet\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:27.296044Z","iopub.execute_input":"2024-10-10T23:29:27.296394Z","iopub.status.idle":"2024-10-10T23:29:27.351133Z","shell.execute_reply.started":"2024-10-10T23:29:27.296360Z","shell.execute_reply":"2024-10-10T23:29:27.350254Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ stack_2 (\u001b[38;5;33mStack\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │ \u001b[38;5;34m3\u001b[0m)                │            │ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ get_item_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ stack_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ resnet101           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │ \u001b[38;5;34m42,658,176\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ resnet101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m2,098,176\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m1,049,600\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │      \u001b[38;5;34m1,026\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ stack_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ stack_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ resnet101           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">42,658,176</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,331,778\u001b[0m (176.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,331,778</span> (176.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,673,602\u001b[0m (14.01 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,673,602</span> (14.01 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,658,176\u001b[0m (162.73 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,658,176</span> (162.73 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":" optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)  # for clipping gradients by norm\n\n# # Compile the model\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:27.353045Z","iopub.execute_input":"2024-10-10T23:29:27.353296Z","iopub.status.idle":"2024-10-10T23:29:27.365775Z","shell.execute_reply.started":"2024-10-10T23:29:27.353274Z","shell.execute_reply":"2024-10-10T23:29:27.364847Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n# Réduire le taux d'apprentissage si la validation loss stagne\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_lr=1e-5)\n# Entraîner le modèle avec les données d'entraînement et de validation\nmy_model = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    callbacks=[reduce_lr]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:27.366922Z","iopub.execute_input":"2024-10-10T23:29:27.367580Z","iopub.status.idle":"2024-10-10T23:29:30.748169Z","shell.execute_reply.started":"2024-10-10T23:29:27.367548Z","shell.execute_reply":"2024-10-10T23:29:30.746816Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle avec les données d'entraînement et de validation\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:619\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n","\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 2), output.shape=(None, 2)"],"ename":"ValueError","evalue":"Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 2), output.shape=(None, 2)","output_type":"error"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(val_dataset)  # Utilisez val_dataset ou test_dataset si vous en avez un","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:30.749399Z","iopub.status.idle":"2024-10-10T23:29:30.749903Z","shell.execute_reply.started":"2024-10-10T23:29:30.749658Z","shell.execute_reply":"2024-10-10T23:29:30.749678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extraction des données d'accuracy et de loss\ntrain_accuracy = my_model.history['accuracy']\nval_accuracy = my_model.history['val_accuracy']\ntrain_loss = my_model.history['loss']\nval_loss = my_model.history['val_loss']\n\nepochs = range(1, len(train_accuracy) + 1)\n\n# Plot de l'accuracy\nplt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.legend()\n\n# Plot de la loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:30.751196Z","iopub.status.idle":"2024-10-10T23:29:30.751682Z","shell.execute_reply.started":"2024-10-10T23:29:30.751430Z","shell.execute_reply":"2024-10-10T23:29:30.751451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### from tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n\nclass_names = list(train_dataset.class_indices.keys())\n#print(\"Class Names:\", class_names)\n#print(\"-\" * 40)\nimg_path = '/kaggle/input/intern/final_image_with_black_background.png'\nimage = cv2.imread(img_path)\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image_rgb)\nplt.axis('off')  # Masquer les axes\nplt.show()\nimg = load_img(img_path, target_size=(256, 256))\nimg_array = img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to create a batch\npredictions = model.predict(img_array)\npredicted_class_index = np.argmax(predictions[0])\npredicted_class_name = class_names[predicted_class_index]\n#print(predictions)\n#print(\"-\" * 40)\n#print('Predicted class index:', predicted_class_index)\n#print(\"-\" * 40)\nprint('Predicted class name:', predicted_class_name)\n#print(\"-\" * 40)\nif predicted_class_name == 'Tomato___healthy':\n    print('plant is healthy, no need to do treatment')\nelse:\n    print('plant is diseased , it needs treatment')\nprint(\"-\" * 40)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:30.753263Z","iopub.status.idle":"2024-10-10T23:29:30.753737Z","shell.execute_reply.started":"2024-10-10T23:29:30.753497Z","shell.execute_reply":"2024-10-10T23:29:30.753516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Make predictions\n# Predict class probabilities for the validation set\nval_predictions = model.predict(val_dataset)\n\n# Step 2: Convert predictions to class labels\n# Get the class with the highest probability for each prediction\nval_predicted_classes = np.argmax(val_predictions, axis=1)\n\n# Step 3: Get true labels from the validation generator\n# Since val_generator.classes gives the true labels of the validation data\nval_true_classes = val_dataset.classes\n\n# Step 4: Generate the confusion matrix\nconf_matrix = confusion_matrix(val_true_classes, val_predicted_classes)\n\n# Step 5: Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=val_dataset.class_indices.keys(), yticklabels=val_dataset.class_indices.keys())\nplt.ylabel('True Labels')\nplt.xlabel('Predicted Labels')\nplt.title('Matrice de confusion M3: detection ')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T23:29:30.754963Z","iopub.status.idle":"2024-10-10T23:29:30.755435Z","shell.execute_reply.started":"2024-10-10T23:29:30.755180Z","shell.execute_reply":"2024-10-10T23:29:30.755199Z"},"trusted":true},"execution_count":null,"outputs":[]}]}